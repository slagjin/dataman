---
layout: post
title: "Hive环境变量设置"
categories: 离线技术栈
tags: [Hive]
author:
  - Slags jin
---

-- 常用设置	
set mapreduce.job.name=dwd_prd_news_applist_di;

set  yarn.app.mapreduce.am.resource.mb=8196;

set mapreduce.reduce.memory.mb=4096; 
set mapreduce.reduce.java.opts=-Xmx4000M -XX:+UseSerialGC;
set mapreduce.map.memory.mb=4096; 
set mapreduce.map.java.opts=-Xmx4000M -XX:+UseSerialGC;

set hive.merge.mapfiles=true;
set hive.merge.mapredfiles = true;
set hive.merge.size.per.task=2048000000;
set hive.merge.smallfiles.avgsize=2048000000;


set hive.exec.dynamic.partition=true;  
set hive.exec.dynamic.partition.mode=nonstrict;

set mapreduce.job.reduce.slowstart.completedmaps=1;

set hive.auto.convert.join=true;
set hive.mapjoin.smalltable.filesize=50000000;
set  hive.map.aggr=true;
set  hive.groupby.skewindata=true;








union all的时候，系统资源足够的情况下，为了加快hive处理速度，可以设置如下参数实现并发执行
	set mapred.job.priority=VERY_HIGH;
	set hive.exec.parallel=true;


动态分区
	set hive.exec.dynamic.partition=true;  
	set hive.exec.dynamic.partition.mode=nonstrict;  
动态分区设置数量
-- set hive.exec.max.dynamic.partitions.pernode=100000;
-- set hive.exec.max.dynamic.partitions.pernode.Maximum=100000;

set hive.exec.max.dynamic.partitions=100000;
set hive.exec.max.created.files=100000;
set hive.limit.query.max.table.partition=-1;

 设置map reduce个数
		set hive.exec.reducers.bytes.per.reducer=2048000000;-- 每个reduce 可以处理的数据量
		-- 设置map capacity
			set mapred.job.map.capacity=2000;
			set mapred.job.reduce.capacity=2000;

		-- 设置每个reduce的大小
			set hive.exec.reducers.bytes.per.reducer=500000000; 
		-- 直接设置个数
			set mapred.reduce.tasks = 15;



-- 小文件的合并

输入合并
	
	    set mapred.max.split.size=2048000000;--每个Map最大输入大小设置为2GB（单位：字节）
--         set mapred.min.split.size.per.node=100000000;
--         set mapred.min.split.size.per.rack=100000000;
        set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;--执行Map前进行小文件合并
输出合并
	set hive.merge.mapfiles = true;--设置map端输出进行合并，默认为true
	set hive.merge.mapredfiles = true;--设置reduce端输出进行合并，默认为false
	set hive.merge.size.per.task = 1024000000; --合并文件的大小
	set hive.merge.smallfiles.avgsize = 1024000000;--当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge

内存限制
	set mapreduce.reduce.memory.mb=6144; 
	set mapreduce.reduce.java.opts=-Xmx4608M -XX:+UseSerialGC;
	set mapreduce.map.memory.mb=6144; 
	set mapreduce.map.java.opts=-Xmx4608M -XX:+UseSerialGC;
	        
	set mapreduce.reduce.memory.mb=6144; 
	set mapreduce.reduce.java.opts=-Xmx5120M -XX:+UseSerialGC;
	set mapreduce.map.memory.mb=6144; 
	set mapreduce.map.java.opts=-Xmx5120M -XX:+UseSerialGC;

-- hive 压缩算法
		io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,
								org.apache.hadoop.io.compress.GzipCodec,
								org.apache.hadoop.io.compress.BZip2Codec,
								org.apache.hadoop.io.compress.DeflateCodec,
								org.apache.hadoop.io.compress.SnappyCodec,
								org.apache.hadoop.io.compress.Lz4Codec


Map 输出阶段 
	#开启 hive 中间传输数据压缩功能
	 	 set hive.exec.compress.intermediate=true;
	#开启 mapreduce 中 map 输出压缩功能
		 set mapreduce.map.output.compress=true;
	#设置 mapreduce 中 map 输出数据的压缩方式
		 set mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;

Reduce 数据阶段
	#开启 hive 最终输出数据压缩功能
		set hive.exec.compress.output=true;
	#开启 mapreduce 最终输出数据压缩
	 	set mapreduce.output.fileoutputformat.compress=true;
	#设置 mapreduce 最终数据输出压缩方式
		set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;
	#设置 mapreduce 最终数据输出压缩为块压缩
		set mapreduce.output.fileoutputformat.compress.type=BLOCK;


同上
-- hive 压缩
		-- 任务中间压缩
			set hive.exec.compress.intermediate=true;
			set hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
			-- set hive.intermediate.compression.type=BLOCK;

-- map/reduce 输出压缩
			set hive.exec.compress.output=true;
			set mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
			-- set mapred.output.compression.type=BLOCK;
			set mapred.output.compress=true;
同上
-- 使用Snappy压缩文件
	set hive.exec.compress.output=true; --默认false，是否对输出结果压缩
        -- 压缩格式设置，一共三种压缩方式（NONE, RECORD,BLOCK），BLOCK压缩率最高，一般用BLOCK。 
	    -- set mapred.output.compression.type=BLOCK;--hadoop输出结果以块分割
	set mapred.output.compress=true;
	set mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
	
	suffer压缩
	set hive.exec.compress.intermediate=true;--suffer过程压缩
	set hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;
	



防止文件数太多，内存溢出 appmarest的内存设置
	set yarn.app.mapreduce.am.resource.mb=32768;
设置split量
	set mapreduce.input.fileinputformat.split.minsize=100000000;
	set mapreduce.input.fileinputformat.split.maxsize=200000000;
数据倾斜
	set  hive.map.aggr=true;
	set   hive.groupby.skewindata=true;

大小表join mapjoin 
	set  hive.auto.convert.join = true; 
	set hive.mapjoin.smalltable.filesize = 50000000; --mapjoin 小表的阀值50M

add  jar hdfs://hz-cluster8/user/idc/hive/udf/qianyuxiang/idprocessor-1.0-SNAPSHOT-jar-with-dependencies.jar;
create temporary function  UdcUrsEncryptHiveUseHDFSParams as 'com.netease.idc.crypto.hdfs.UdcUrsEncryptHiveUseHDFSParams';


	
这个参数可以控制当map任务执行到哪个比例的时候就可以开始为reduce task申请资源。
		set mapred.reduce.slowstart.completed.maps = 0.99;
		默认配置为0.05，那么map task在执行到5%的时候就开始为reduce进行申请资源，开始执行reduce操作，reduce可以开始进行拷贝map结果数据和做reduce shuffle操作。

	一下4句配置原则上不允许在代码中出现
	如必须，最大值设置为 6144
	set  mapreduce.map.memory.mb=32768;
	set mapreduce.reduce.memory.mb=32768;
	set mapreduce.reduce.java.opts=-Xmx32768M -XX:+UseSerialGC;
	set mapreduce.map.java.opts=-Xmx32768M -XX:+UseSerialGC;


	-- hive文件格式
			TEXTFILE: 默认格式，存储方式为行存储，
						数据不做压缩，磁盘开销大。
						如需压缩，可使用Gzip,Bzip2压缩算法，但是不会对数据进行切分;
			SEQUENCEFILE: 二进制文件，具有使用方便、可分割、可压缩.	
						 SequenceFile支持三种压缩选择：NONE，RECORD(压缩率低)，BLOCK(常用且压缩性能最好);
			RCFILE: RCFILE是一种行列存储相结合的存储方式;
			ORCFILE: 数据按照行分块，每个块按照列存储，压缩效率高
			parquet: 行存储,支持压缩，可切分

		行存储的特点： 查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行
						存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。
		列存储的特点： 因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；
						每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法



--map输入的小文件合并
--set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; --已经默认开启了
set mapred.min.split.size=268435456;--最小map文件大小256M
set mapred.max.split.size=536870912; --小于500M的一个map,大于500M的要分割多个map
set mapred.min.split.size.per.node=536870912; --小于500M的合并datanode上的文件合并
set mapred.min.split.size.per.rack=536870912; --小于500M的交换机上的文件合并

--map和reduce输出端的文件合并
--set hive.merge.mapredfiles = true;
set hive.merge.mapfiles=true;
set hive.merge.size.per.task=536870912;
set hive.merge.smallfiles.avgsize=536870912;
--set hive.exec.reducers.bytes.per.reducer=1024000000; --改参数会增加stage数量

--map和reduce的内存资源设置
set yarn.app.mapreduce.am.resource.mb=8196;
--set mapreduce.map.memory.mb=8192; 
--set mapreduce.map.java.opts=-Xmx7372M -XX:+UseSerialGC;

--map端join
SET hive.auto.convert.join=true;
set hive.mapjoin.smalltable.filesize=50000000;
set mapreduce.job.reduce.slowstart.completedmaps=1;

add jar hdfs://hz-cluster8/user/idc/hive/udf/udfs-1.0-jar-with-dependencies.jar;
create temporary function musicContentDecorder as 'com.netease.hive.udf.music.MusicImeiDecorderUDF';

