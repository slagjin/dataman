---
layout: post
title: "Hive之存储格式"
categories: 离线技术栈
tags: [Hive]
author:
  - Slags jin
---


1.textfile
Hive数据表的默认格式，数据不做压缩，磁盘开销大，数据解析开销大。存储方式：行存储。

可以使用Gzip压缩算法，但压缩后的文件不支持split。

在反序列化过程中，必须逐个字符判断是不是分隔符和行结束符，因此反序列化开销会比SequenceFile高几十倍。

2.RCFile
存储方式：数据按行分块，每块按列存储。结合了行存储和列存储的优点：

首先，RCFile 保证同一行的数据位于同一节点，因此元组重构的开销很低

其次，像列存储一样，RCFile 能够利用列维度的数据压缩，并且能跳过不必要的列读取

数据追加：RCFile不支持任意方式的数据写操作，仅提供一种追加接口，这是因为底层的 HDFS当前仅仅支持数据追加写文件尾部。

行组大小：行组变大有助于提高数据压缩的效率，但是可能会损害数据的读取性能，因为这样增加了 Lazy 解压性能的消耗。而且行组变大会占用更多的内存，这会影响并发执行的其他MR作业。 考虑到存储空间和查询效率两个方面，Facebook 选择 4MB 作为默认的行组大小，当然也允许用户自行选择参数进行配置。

3.ORCFile
存储方式：数据按行分块，每块按照列存储。 

压缩快，可切分，快速列存取。效率比rcfile高，是rcfile的改良版本。

支持各种复杂的数据类型，比如datetime,decimal,以及复杂的struct

4.Sequence Files
压缩数据文件可以节省磁盘空间，但Hadoop中有些原生压缩文件的缺点之一就是不支持分割。支持分割的文件可以并行的有多个mapper程序处理大数据文件，大多数文件不支持可分割是因为这些文件只能从头开始读。Sequence File是可分割的文件格式，支持Hadoop的block级压缩。

Hadoop API提供的一种二进制文件，以key-value的形式序列化到文件中。存储方式：行存储。

sequencefile支持三种压缩选择：NONE，RECORD，BLOCK。Record压缩率低，RECORD是默认选项，通常BLOCK会带来较RECORD更好的压缩性能。

优势是文件和hadoop api中的MapFile是相互兼容的

注：建表时默认为这个格式，导入数据时会直接把数据文件拷贝到hdfs上不进行处理。SequenceFile、RCFile、ORC格式的表不能直接从本地文件导入数据，数据要先导入到TextFile格式的表中，然后再从TextFile表中用insert导入到SequenceFile、RCFile表中。

列式存储和行式存储
首先我们看一下一张表的存储格式



1.1 行式存储



1.2 列式存储

 

1.3列式存储和行式存储的比较

行式存储

优点：

相关的数据是保存在一起，比较符合面向对象的思维，因为一行数据就是一条记录

这种存储格式比较方便进行INSERT/UPDATE操作

缺点：

如果查询只涉及某几个列，它会把整行数据都读取出来，不能跳过不必要的列读取。当然数据比较少，一般没啥问题，如果数据量比较大就比较影响性能

由于每一行中，列的数据类型不一致，导致不容易获得一个极高的压缩比，也就是空间利用率不高

不是所有的列都适合作为索引

列式存储

优点：

查询时，只有涉及到的列才会被查询，不会把所有列都查询出来，即可以跳过不必要的列查询

高效的压缩率，不仅节省储存空间也节省计算内存和CPU

任何列都可以作为索引

缺点：

INSERT/UPDATE很麻烦或者不方便

不适合扫描小量的数据

文件读写与序列化
记录编码由InputFormat控制

记录解码由SerDe控制，使用OutputFormat将查询输出

以及SerDe

Hive中，默认使用的是TextInputFormat，一行表示一条记录。在每条记录(一行中)，默认使用^A分割各个字段。

在有些时候，我们往往面对多行，结构化的文档，并需要将其导入Hive处理，此时，就需要自定义InputFormat、OutputFormat，以及SerDe。

当hive读取hdfs文件时：

(1) 调用InputFormat，将文件切成不同的文档。每篇文档即一行(Row)。

(2) 调用SerDe的Deserializer，将一行(Row)，切分为各个字段。

 

Stored as orc 和stored as INPUTFORMAT… OUTPUTFORMAT…的区别？

当我们使用Stored as orc的时候，其实隐式的指定了下面三个配置：

1 SERDE:org.apache.hadoop.hive.ql.io.orc.OrcSerde

2 INPUTFORMAT: org.apache.hadoop.hive.ql.io.orc.InputFormat

3 OUTPUTFORMAT: org.apache.hadoop.hive.ql.io.orc.OutputFormat

当我们显式的指定stored as INPUTFORMAT… OUTPUTFORMAT…：

此时SERDE并没有指定，使用的是默认的SERDE，或者配置文件中的SERDE